{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8cccdb3",
   "metadata": {},
   "source": [
    "## Next Word Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0167d0e9",
   "metadata": {},
   "source": [
    "The Next Word Prediction Models are used in applications like messaging apps, search engines, virtual assistants, and autocorrect features on smartphones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57034e4c",
   "metadata": {},
   "source": [
    "Next word prediction is a language modelling task in Machine Learning that aims to predict the most probable word or sequence of words that follows a given input context. This task utilizes statistical patterns and linguistic structures to generate accurate predictions based on the context provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0c9a57",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "    1. start by collecting a diverse dataset of text documents\n",
    "    2. preprocess the data by cleaning and tokenizing it\n",
    "    3. prepare the data by creating input-output pairs\n",
    "    4. engineer features such as word embeddings\n",
    "    5. select an appropriate model like an LSTM or GPT \n",
    "    6. train the model on the dataset while adjusting hyperparameters\n",
    "    7. improve the model by experimenting with different techniques and architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86b5f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff6e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the text file\n",
    "with open('book/sherlock-holm.es_stories_plain-text_advs.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b2901d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8200\n"
     ]
    }
   ],
   "source": [
    "#tokenize the txt to create a sequence\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26396240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create input-output pairs \n",
    "input_sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ddfe31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "501281df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad the input sequence to have equal length\n",
    "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f6964a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    1, 1561],\n",
       "       [   0,    0,    0, ...,    1, 1561,    5],\n",
       "       [   0,    0,    0, ..., 1561,    5,  129],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    1, 8198, 8199],\n",
       "       [   0,    0,    0, ..., 8198, 8199, 3187],\n",
       "       [   0,    0,    0, ..., 8199, 3187, 3186]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79c6a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the sequence into input and output\n",
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7162a924",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.88 GiB for an array with shape (96314, 8200) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#convert output to one-hot encoding vectors\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(y, num_classes\u001b[38;5;241m=\u001b[39mtotal_words))\n",
      "File \u001b[1;32md:\\python 3.9.6\\lib\\site-packages\\keras\\src\\utils\\numerical_utils.py:88\u001b[0m, in \u001b[0;36mto_categorical\u001b[1;34m(x, num_classes)\u001b[0m\n\u001b[0;32m     86\u001b[0m     num_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(x) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     87\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 88\u001b[0m categorical \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m categorical[np\u001b[38;5;241m.\u001b[39marange(batch_size), x] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     90\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m input_shape \u001b[38;5;241m+\u001b[39m (num_classes,)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.88 GiB for an array with shape (96314, 8200) and data type float64"
     ]
    }
   ],
   "source": [
    "#convert output to one-hot encoding vectors\n",
    "y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5dd1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
